{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Rb0W1FmzlLZr"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from scipy.stats import multivariate_normal, weibull_min\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['text.usetex'] = True\n",
    "plt.rcParams['pgf.rcfonts'] = False\n",
    "plt.rcParams['pgf.texsystem'] = 'pdflatex'\n",
    "plt.rcParams['pgf.preamble'] = '\\n'.join([\n",
    "    r'\\usepackage[T1, T2A]{fontenc}',\n",
    "    r'\\usepackage[utf8]{inputenc}',\n",
    "    r'\\usepackage[english, russian]{babel}'\n",
    "    ])\n",
    "plt.rc('font', family='serif')\n",
    "plt.switch_backend('pgf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_colors = ['green', 'red', 'gray', 'blue', 'purple', 'orange']\n",
    "plt.rcParams['axes.prop_cycle'] = plt.cycler(color=my_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.size']=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "OmiLsT7hlXPd"
   },
   "outputs": [],
   "source": [
    "def stationary_distr(Q):\n",
    "  evals, evecs = np.linalg.eig(Q.T)\n",
    "  evec1 = evecs[:,np.isclose(evals, 1)]\n",
    "\n",
    "#Since np.isclose will return an array, we've indexed with an array\n",
    "#so we still have our 2nd axis.  Get rid of it, since it's only size 1.\n",
    "  evec1 = evec1[:,0]\n",
    "\n",
    "  stationary = evec1 / evec1.sum()\n",
    "\n",
    "#eigs finds complex eigenvalues and eigenvectors, so you'll want the real part.\n",
    "  stationary = stationary.real\n",
    "  return stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Q_Qg-mn_lzqY"
   },
   "outputs": [],
   "source": [
    "def init_X(pi, U=np.random.uniform(0, 1, 1)):\n",
    "  cumm = 0\n",
    "  for i in range(len(pi)):\n",
    "    cumm += pi[i]\n",
    "    if cumm > U:\n",
    "      return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Xuib_E9Yl1hu"
   },
   "outputs": [],
   "source": [
    "def scale(row):\n",
    "  s = np.sum(row)\n",
    "  return row/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "yvoST3_1qDxJ"
   },
   "outputs": [],
   "source": [
    "def model_X(dim_X, markov_chain, H, T):\n",
    "  Lambda, pi, f, g = markov_chain\n",
    "  \n",
    "  # state\n",
    "  X_grid_length = int(T/H)\n",
    "  U = np.random.uniform(0, 1, X_grid_length)\n",
    "  X_grid = np.arange(0, X_grid_length)\n",
    "  X = np.empty(X_grid_length, dtype = np.int8)\n",
    "  X[0] = init_X(pi)\n",
    "  P = np.eye(dim_X) + H * Lambda\n",
    "  for i in tqdm(X_grid[1:]):\n",
    "    P_i = P[X[i - 1]]\n",
    "    X[i] = init_X(scale(P_i), U[i])\n",
    "  return X, X_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Q_gSRj87qNoH"
   },
   "outputs": [],
   "source": [
    "def model_Y(X, dim_Y, markov_chain, discretization, T):\n",
    "  H, h = discretization\n",
    "  Lambda, pi, f, g = markov_chain\n",
    "  # observations\n",
    "  Y_grid_length = int(T/h)\n",
    "\n",
    "  W =  np.random.multivariate_normal(np.zeros(dim_Y), np.eye(dim_Y), Y_grid_length)\n",
    "\n",
    "  Y_grid = np.arange(0, Y_grid_length)\n",
    "  Y = np.empty((Y_grid_length, dim_Y))\n",
    "  S = np.empty((Y_grid_length, dim_Y))\n",
    "  S[0] = np.ones(dim_Y)\n",
    "  for i in tqdm(Y_grid[1:]):\n",
    "    Y[i] = np.diag(S[i-1]) @ f[X[i * int(h/H)]] * h + np.diag(S[i-1]) @ W[i] @ np.linalg.cholesky(h * g[X[i * int(h/H)]])\n",
    "    S[i] = S[i - 1] + Y[i]\n",
    "  return Y, S, Y_grid  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "oOzQZgtAdAVC"
   },
   "outputs": [],
   "source": [
    "def model_Y_easy(X, dim_Y, markov_chain, discretization, T):\n",
    "  H, h = discretization\n",
    "  Lambda, pi, f, g = markov_chain\n",
    "  # observations\n",
    "  Y_grid_length = int(T/h)\n",
    "\n",
    "  W =  np.random.normal(0, 1, Y_grid_length)\n",
    "\n",
    "  Y_grid = np.arange(0, Y_grid_length)\n",
    "  Y = np.empty(Y_grid_length)\n",
    "  S = np.empty(Y_grid_length)\n",
    "  S[0] = 1\n",
    "  for i in tqdm(Y_grid[1:]):\n",
    "    Y[i] = S[i-1] * f[0] * h + S[i-1] * W[i] * np.sqrt(h * g[0])\n",
    "    S[i] = S[i - 1] + Y[i]\n",
    "  return Y, S, Y_grid  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "cJEyBGn8nXY9"
   },
   "outputs": [],
   "source": [
    "def to_sums(Y, start=0):\n",
    "  sum_Y = np.empty(Y.size)\n",
    "  sum_Y[0] = start\n",
    "  for i in tqdm(range(sum_Y.size)[1:]):\n",
    "    sum_Y[i] = sum_Y[i - 1] + Y[i - 1]\n",
    "  return sum_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ziN7Os4wTdrl"
   },
   "outputs": [],
   "source": [
    "def model_observations(Y, X, weibull_distr_params, discretization, Y_grid, dimensions):\n",
    "  dim_X, dim_Y = dimensions\n",
    "  H, h = discretization\n",
    "  i = 0\n",
    "  t = np.empty(Y_grid.size)\n",
    "  S = np.empty(Y_grid.size)\n",
    "  curr_pos = 0\n",
    "  pbar = tqdm(total=Y_grid.size)\n",
    "  while i < Y_grid.size:\n",
    "    prev = i\n",
    "    weibull = weibull_min.rvs(weibull_distr_params[X[i * int(h/H)]][0], size=1, scale=weibull_distr_params[X[i * int(h/H)]][1])\n",
    "    w_int = int(np.around(weibull * h ** (-1), 0))\n",
    "    weibull_round = w_int * h\n",
    "    t[curr_pos] = weibull_round\n",
    "    i += w_int\n",
    "    if i < len(Y_grid):\n",
    "      S[curr_pos] = np.log(Y[i] / Y[prev])\n",
    "    curr_pos += 1\n",
    "    pbar.update(i - prev)\n",
    "  pbar.close()\n",
    "  return S[:curr_pos - 1], t[:curr_pos - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "-lUy26GJdmGY"
   },
   "outputs": [],
   "source": [
    "def model_trades(S, t, window_orig, T):\n",
    "  mean_S = np.empty(int(T/window_orig))\n",
    "  mean_t = np.empty(int(T/window_orig))\n",
    "  cumm_T = np.empty(int(T/window_orig))\n",
    "  index_of_left = 0\n",
    "  curr_index = 0\n",
    "  window = window_orig\n",
    "  for i in tqdm(range(t.size)):\n",
    "    if np.sum(t[index_of_left:i]) >= window:\n",
    "      mean_S[curr_index] = np.sum(S[index_of_left:i]) / np.sqrt(window)  # or should be window?\n",
    "      mean_t[curr_index] = (i - index_of_left) / np.sqrt(window)  # np.sum(t[index_of_left:i]) / np.sqrt(window_orig) \n",
    "      cumm_T[curr_index] = i - index_of_left\n",
    "      window = window + window_orig - np.sum(t[index_of_left:i])\n",
    "      index_of_left = i\n",
    "      curr_index += 1\n",
    "  left_time = np.sum(t[index_of_left:])\n",
    "  mean_S[curr_index] = np.sum(S[index_of_left:]) / np.sqrt(left_time)\n",
    "  mean_t[curr_index] = (t.size - index_of_left) / np.sqrt(left_time)\n",
    "  cumm_T[curr_index] = t.size - index_of_left\n",
    "  return mean_S, mean_t, cumm_T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "fHvQKwW3CGhB"
   },
   "outputs": [],
   "source": [
    "def filter(U, h, window, markov_chain, T, weibull_distr_params, dim_X):\n",
    "  Lambda, pi, f, g = markov_chain\n",
    "  g = g.flatten()\n",
    "  f = f.flatten()\n",
    "  X_pred_grid_length = int(T/h)\n",
    "  X_pred = np.empty((X_pred_grid_length, dim_X), dtype=np.float32)\n",
    "  X_pred_grid = np.arange(0, X_pred_grid_length)\n",
    "  N_0 = np.empty((dim_X, 2))\n",
    "  N_1 = np.empty((dim_X, 2, 2))\n",
    "  for i in range(dim_X):\n",
    "    m_l = weibull_min.mean(weibull_distr_params[i][0], scale=weibull_distr_params[i][1])\n",
    "    d_l = weibull_min.var(weibull_distr_params[i][0], scale=weibull_distr_params[i][1])\n",
    "    N_0[i] = np.array([np.sqrt(window) / m_l, (f[i] - g[i] / 2) * np.sqrt(window)])\n",
    "    N_1[i] = np.diag([d_l / (m_l ** 3), g[i]])  # m_l or a_l?\n",
    "  \n",
    "  P_T = (np.eye(dim_X) + h * Lambda).T\n",
    "  X_pred[0] = pi\n",
    "  for i in tqdm(X_pred_grid[1:]):\n",
    "    X_pred[i] = P_T @ X_pred[i-1]\n",
    "    if i % (int(window / h)) == 0:\n",
    "      Z = np.empty((dim_X))\n",
    "      for j in range(dim_X):\n",
    "        Z[j] = X_pred[i][j] * multivariate_normal.pdf(U[i // int((window / h))], N_0[j], N_1[j])\n",
    "      if np.sum(Z) == 0:\n",
    "        print(i)\n",
    "      X_pred[i] = Z / np.sum(Z)\n",
    "  return X_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "cmje1GhcONqt"
   },
   "outputs": [],
   "source": [
    "def draw3dgraphs(iter, mean_S, mean_t, markov_chain, weibull_distr_params, dimensions, elev, azim):\n",
    "    #%matplotlib widget\n",
    "    Lambda, pi, f, g = markov_chain\n",
    "    dim_X, dim_Y = dimensions\n",
    "    g = g.flatten()\n",
    "    f = f.flatten()\n",
    "\n",
    "\n",
    "    N_0 = np.empty((dim_X, 2))\n",
    "    N_1 = np.empty((dim_X, 2, 2))\n",
    "    for i in range(dim_X):\n",
    "        m_l = weibull_min.mean(weibull_distr_params[i][0], scale=weibull_distr_params[i][1])\n",
    "        d_l = weibull_min.var(weibull_distr_params[i][0], scale=weibull_distr_params[i][1])\n",
    "        N_0[i] = np.array([np.sqrt(window) / m_l, (f[i] - g[i] / 2) * np.sqrt(window)])\n",
    "        N_1[i] = np.diag([d_l / (m_l ** 3), g[i]])  # m_l or a_l?\n",
    "\n",
    "    x = mean_t\n",
    "    y = mean_S\n",
    "\n",
    "    t_range = np.max(mean_t) - np.min(mean_t)\n",
    "    S_range = np.max(mean_S) - np.min(mean_S)\n",
    "\n",
    "    bins = 40\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 7), dpi=240)\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    hist, xedges, yedges = np.histogram2d(x, y, bins=bins, range=[[np.min(mean_t), np.max(mean_t)], [np.min(mean_S), np.max(mean_S)]], density=True)\n",
    "\n",
    "    xpos, ypos = np.meshgrid(xedges[:-1] + t_range / (bins ** 2), yedges[:-1] + S_range / (bins ** 2), indexing=\"ij\")\n",
    "    xpos = xpos.ravel()\n",
    "    ypos = ypos.ravel()\n",
    "    zpos = 0\n",
    "\n",
    "    dx = t_range / (bins) * np.ones_like(zpos)\n",
    "    dy = S_range / (bins) * np.ones_like(zpos)\n",
    "    dz = hist.ravel()\n",
    "    ax.view_init(elev=elev, azim=azim)\n",
    "    ax.auto_scale_xyz([], [], [])\n",
    "    ax.bar3d(xpos, ypos, zpos, dx, dy, dz, zsort='average', alpha=0.7, color='green', zorder=2,label=\"Гистограмма\")\n",
    "\n",
    "    #y = np.linspace(np.min(mean_S), np.max(mean_S), 1600)\n",
    "    #x = np.linspace(np.min(mean_t), np.max(mean_t), 1600)\n",
    "    #X, Y = np.meshgrid(x[:-1], y[:-1], indexing='ij')\n",
    "    X, Y = np.meshgrid(xedges + t_range / (bins ** 2), yedges + S_range / (bins ** 2), indexing=\"ij\")\n",
    "    zs = np.zeros(X.size)\n",
    "    for j in range(dim_X):\n",
    "        zs += multivariate_normal.pdf(np.vstack([X.ravel(), Y.ravel()]).T, N_0[j], N_1[j]) * pi[j]\n",
    "    Z = zs.reshape(X.shape)\n",
    "    #wireframe=ax.plot_wireframe(X, Y, Z, color='red', alpha=0.8, linewidth=2, zorder=1, label=\"Теоритическая гауссиана смеси\")\n",
    "    ax.plot_surface(X, Y, Z, color=\"red\", shade=False, edgecolor=\"red\", alpha=0.7)\n",
    "    #ax.plot_surface(X, Y, Z, color='red', linewidth=1, alpha=0.8)\n",
    "    #ax.view_init(elev=10., azim=270)\n",
    "    #plt.title(iter+\"агрегированных наблюдений\")\n",
    "\n",
    "    import mpl_toolkits.mplot3d.art3d as art3d \n",
    "    \n",
    "    bar_legend = art3d.Line3D([], [], [], color='green', label='Гистограмма')\n",
    "    wireframe_legend = art3d.Line3D([], [], [], color='red', label='Теоритическая гауссиана смеси')\n",
    "\n",
    "# Add the lines to the plot and legend\n",
    "    ax.add_artist(bar_legend)\n",
    "    ax.add_artist(wireframe_legend)\n",
    "    ax.legend(handles=[bar_legend, wireframe_legend])\n",
    "    \n",
    "    plt.savefig(\"histogram&gaussian.pgf\", bbox_inches='tight')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Zu3vVqPrOPur"
   },
   "outputs": [],
   "source": [
    "def draw2dgraphs(iter, mean_S, mean_t, markov_chain, weibull_distr_params, dimensions):\n",
    "    #%matplotlib widget\n",
    "    Lambda, pi, f, g = markov_chain\n",
    "    dim_X, dim_Y = dimensions\n",
    "    g = g.flatten()\n",
    "    f = f.flatten()\n",
    "\n",
    "    N_0 = np.empty((dim_X, 2))\n",
    "    N_1 = np.empty((dim_X, 2, 2))\n",
    "    for i in range(dim_X):\n",
    "        m_l = weibull_min.mean(weibull_distr_params[i][0], scale=weibull_distr_params[i][1])\n",
    "        d_l = weibull_min.var(weibull_distr_params[i][0], scale=weibull_distr_params[i][1])\n",
    "        N_0[i] = np.array([np.sqrt(window) / m_l, (f[i] - g[i] / 2) * np.sqrt(window)])\n",
    "        N_1[i] = np.diag([d_l / (m_l ** 3), g[i]])  # m_l or a_l?\n",
    "\n",
    "\n",
    "    bins = 30\n",
    "\n",
    "    x = np.linspace(np.min(mean_t), np.max(mean_t), 500)\n",
    "    y = np.linspace(np.min(mean_S), np.max(mean_S), 500)\n",
    "    fig = plt.figure(figsize=(12, 7), dpi=240)\n",
    "    z = np.zeros(x.size)\n",
    "    for i in range(dim_X):\n",
    "        z += pi[i] * multivariate_normal.pdf(x, N_0[i][0], N_1[i][0][0])\n",
    "        plt.plot(x, multivariate_normal.pdf(x, N_0[i][0], N_1[i][0][0]) * pi[i], color='yellow', label='Гауссианы компонент смеси, умноженные на вероятности')\n",
    "\n",
    "    #2d graphs\n",
    "    plt.hist(mean_t, bins, density=True, label='Гистограмма')\n",
    "    plt.plot(x, z, label='Теоритическая гауссиана смеси')\n",
    "    #plt.title(iter + \"агрегированных наблюдений за количеством трейдов\")\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    newLabels, newHandles = [], []\n",
    "    for handle, label in zip(handles, labels):\n",
    "        if label not in newLabels:\n",
    "            newLabels.append(label)\n",
    "            newHandles.append(handle)\n",
    "    #plt.legend(newHandles, newLabels, loc='upper right')\n",
    "    \n",
    "    plt.savefig(\"gaussian_of_t.pgf\", bbox_inches='tight')\n",
    "    #plt.show()\n",
    "    \n",
    "    fig = plt.figure(figsize=(12, 7), dpi=240)\n",
    "    z = np.zeros(y.size)\n",
    "    for i in range(dim_X):\n",
    "        z += pi[i] * multivariate_normal.pdf(y, N_0[i][1], N_1[i][1][1])\n",
    "        plt.plot(y, multivariate_normal.pdf(y, N_0[i][1], N_1[i][1][1]) * pi[i], color='yellow', label='Гауссианы компонент смеси, умноженные на вероятности')\n",
    "        \n",
    "    plt.hist(mean_S, bins, density=True, label='Гистограмма')\n",
    "    plt.plot(y, z, label='Теоритическая гауссиана смеси')\n",
    "    #plt.title(iter + \" агрегированных наблюдений за приращениями\")\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    newLabels, newHandles = [], []\n",
    "    for handle, label in zip(handles, labels):\n",
    "        if label not in newLabels:\n",
    "            newLabels.append(label)\n",
    "            newHandles.append(handle)\n",
    "    #plt.legend(newHandles, newLabels, loc='upper right')\n",
    "    plt.savefig(\"gaussian_of_S.pgf\", bbox_inches='tight')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "-0Ja2RMAe4KW"
   },
   "outputs": [],
   "source": [
    "H = 10 ** (-7) # X time\n",
    "h = 10 ** (-7) # Y time\n",
    "T = 1# in minutes\n",
    "\n",
    "seed = 69\n",
    "if seed != 0:\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "dim_X = 4\n",
    "dim_Y = 1\n",
    "\n",
    "Lambda = np.array([[-12.5, 12.5, 0, 0],\n",
    "                    [0, -1000, 1000, 0],\n",
    "                    [0, 0, -250, 250],\n",
    "                    [40, 0, 10, -50]])\n",
    "pi = stationary_distr(np.eye(dim_X) + H * Lambda)\n",
    "f = np.array([[0.07], \n",
    "              [0.03], \n",
    "              [0.02],\n",
    "              [0.025]])\n",
    "g = np.array([np.diag([0.1]), \n",
    "              np.diag([0.5]), \n",
    "              np.diag([0.6]),\n",
    "              np.diag([0.3])])\n",
    "weibull_distr_params = np.array([[1, 0.0000060],  # in article we have alpha = 1/Lambda, beta = k\n",
    "                                 [1.2, 0.0000050],  # k - wiki, scale\n",
    "                                 [1.2, 0.0000055],  #  \n",
    "                                 [1.4, 0.0000070]])\n",
    "markov_chain = (Lambda, pi, f, g)\n",
    "discretization = (H, h)\n",
    "dimensions = (dim_X, dim_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X, X_grid = model_X(dim_X, markov_chain, H, T)\\nY, Y_sum, Y_grid = model_Y(X, dim_Y, markov_chain, discretization, T)'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"X, X_grid = model_X(dim_X, markov_chain, H, T)\n",
    "Y, Y_sum, Y_grid = model_Y(X, dim_Y, markov_chain, discretization, T)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"with open('XandY.npy', 'wb') as f:\\n    np.savez(f, X=X, X_grid=X_grid, Y=Y, Y_grid=Y_grid, Y_sum=Y_sum)\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"with open('XandY.npy', 'wb') as f:\n",
    "    np.savez(f, X=X, X_grid=X_grid, Y=Y, Y_grid=Y_grid, Y_sum=Y_sum)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('XandY.npy', 'rb') as file:\n",
    "    npzfile = np.load(file)\n",
    "    X = npzfile['X'].copy()\n",
    "    X_grid = npzfile['X_grid'].copy()\n",
    "    Y = npzfile['Y'].copy()\n",
    "    Y_grid = npzfile['Y_grid'].copy()\n",
    "    Y_sum = npzfile['Y_sum'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72072072, 0.00900901, 0.04504505, 0.22522523])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000038it [00:07, 1315059.54it/s]                                                                                     \n",
      "100%|██████████████████████████████████████████████████████████████████████| 166104/166104 [00:00<00:00, 267959.08it/s]\n"
     ]
    }
   ],
   "source": [
    "S, t = model_observations(Y_sum, X, weibull_distr_params, discretization, Y_grid, dimensions)\n",
    "window = 10 ** (-4)\n",
    "mean_S, mean_t, cumm_T = model_trades(S, t, window, T)\n",
    "U = np.vstack([mean_t, mean_S]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 9999999/9999999 [00:30<00:00, 333103.61it/s]\n"
     ]
    }
   ],
   "source": [
    "X_pred = filter(U, h, window, markov_chain, T, weibull_distr_params, dim_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166
    },
    "id": "SHP0kdKFh7H9",
    "outputId": "ffb1653c-ddbf-435f-9565-f4c08ae9b0e3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#draw3dgraphs(\"Плотность распределения смеси \", mean_S, mean_t, markov_chain, weibull_distr_params, dimensions,elev=20,azim=-60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "bCLOChXtiESk"
   },
   "outputs": [],
   "source": [
    "draw2dgraphs(\"Плотность распределения смеси \", mean_S, mean_t, markov_chain, weibull_distr_params, dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "argmax = np.argmax(X_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000000,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'plt.figure(figsize=(12, 1), dpi=240)\\n#plt.title(\"Результат фильтрации\")\\nplt.plot(np.arange(0,1,h), X+1, label=\\'Действительное значение\\', zorder=2, lw=0.5)\\nplt.plot(np.arange(0,1,h), argmax+1, label=\\'Оценка\\', zorder=1, lw=0.5)\\nplt.legend(loc=\\'upper right\\')\\nplt.ylabel(\\'Состояние МСП\\')\\nplt.xlabel(\\'Время (год)\\')\\nplt.yticks([1, 2, 3, 4])\\nplt.savefig(\"filtration.pgf\", bbox_inches=\\'tight\\')\\n#plt.show()'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"plt.figure(figsize=(12, 1), dpi=240)\n",
    "#plt.title(\"Результат фильтрации\")\n",
    "plt.plot(np.arange(0,1,h), X+1, label='Действительное значение', zorder=2, lw=0.5)\n",
    "plt.plot(np.arange(0,1,h), argmax+1, label='Оценка', zorder=1, lw=0.5)\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Состояние МСП')\n",
    "plt.xlabel('Время (год)')\n",
    "plt.yticks([1, 2, 3, 4])\n",
    "plt.savefig(\"filtration.pgf\", bbox_inches='tight')\n",
    "#plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xstart=0.15\\nxend=0.2\\n\\ncoor_xstart = int(xstart / h)\\ncoor_xend = int(xend/h)\\n\\nplt.figure(figsize=(12, 1), dpi=240)\\n#plt.title(\"Результат фильтрации по наблюдениям в случайные моменты времени\")\\nplt.plot(np.arange(0,1,h)[coor_xstart:coor_xend], (X+1)[coor_xstart:coor_xend], label=\\'Действительное значение\\', zorder=2)\\nplt.plot(np.arange(0,1,h)[coor_xstart:coor_xend], (argmax+1)[coor_xstart:coor_xend], label=\\'Оценка\\', zorder=1)\\nplt.legend(loc=\\'upper right\\')\\nplt.ylabel(\\'Состояние МСП\\')\\nplt.xlabel(\\'Время (год)\\')\\nplt.yticks([1, 2, 3, 4])\\nplt.savefig(\"filtration_zoom.pgf\", bbox_inches=\\'tight\\')\\n#plt.show()'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"xstart=0.15\n",
    "xend=0.2\n",
    "\n",
    "coor_xstart = int(xstart / h)\n",
    "coor_xend = int(xend/h)\n",
    "\n",
    "plt.figure(figsize=(12, 1), dpi=240)\n",
    "#plt.title(\"Результат фильтрации по наблюдениям в случайные моменты времени\")\n",
    "plt.plot(np.arange(0,1,h)[coor_xstart:coor_xend], (X+1)[coor_xstart:coor_xend], label='Действительное значение', zorder=2)\n",
    "plt.plot(np.arange(0,1,h)[coor_xstart:coor_xend], (argmax+1)[coor_xstart:coor_xend], label='Оценка', zorder=1)\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Состояние МСП')\n",
    "plt.xlabel('Время (год)')\n",
    "plt.yticks([1, 2, 3, 4])\n",
    "plt.savefig(\"filtration_zoom.pgf\", bbox_inches='tight')\n",
    "#plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 7), dpi=240)\n",
    "plt.plot(np.arange(0,1,h), Y_sum)\n",
    "#plt.title('Смоделированная траектория цены акции')\n",
    "plt.xlabel('Время (год)')\n",
    "plt.ylabel('Цена базового финансового актива')\n",
    "plt.savefig(\"stock_trajectory.pgf\", bbox_inches='tight')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 166103/166103 [00:00<00:00, 1950420.99it/s]\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(11, 7), dpi=240)\n",
    "plt.step(to_sums(t), S, where='post')\n",
    "#plt.title('Смоделированный поток трейдов')\n",
    "plt.xlabel('Время (год)')\n",
    "plt.ylabel('Приращение цены базового актива')\n",
    "plt.savefig(\"trades_trajectory.pgf\", bbox_inches='tight')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 166103/166103 [00:00<00:00, 2576055.48it/s]\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(11, 7), dpi=240)\n",
    "plt.step(to_sums(t)[:55] * (250 * 8 * 60), S[:55], where='post')\n",
    "#plt.title('Смоделированный поток трейдов в первые 30 минут')\n",
    "plt.xlabel('Время (минуты)')\n",
    "plt.ylabel('Приращение цены базового актива')\n",
    "plt.savefig(\"trades_trajectory_half_hour.pgf\", bbox_inches='tight')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 166103/166103 [00:00<00:00, 1992451.24it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.   ,  0.252,  1.44 ,  1.752,  2.868,  3.456,  3.672,  3.756,\n",
       "        3.804,  4.608,  5.472,  6.42 ,  7.536,  7.596,  7.872,  8.844,\n",
       "        9.132,  9.588,  9.732, 10.008, 10.44 , 10.98 , 11.232, 11.46 ,\n",
       "       12.276, 12.468, 13.284, 13.692, 14.04 , 14.34 , 14.856, 18.024,\n",
       "       18.564, 19.38 , 19.74 , 19.824, 20.712, 21.096, 21.54 , 21.828,\n",
       "       21.9  , 22.344, 23.52 , 23.676, 24.132, 24.288, 24.348, 24.372,\n",
       "       24.492, 24.708, 24.756, 26.64 , 27.204, 29.664, 31.308])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_sums(t)[:55] * (250 * 8 * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int8)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1e-06"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(t[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "xstart=0\n",
    "xend=1\n",
    "\n",
    "coor_xstart = int(xstart / h)\n",
    "coor_xend = int(xend/h)\n",
    "for i in range(1, dim_X+1):\n",
    "    plt.figure(figsize=(12, 1), dpi=240)\n",
    "    #plt.title(\"Результат фильтрации по наблюдениям в случайные моменты времени (\"+str(i)+\"-состояние)\")\n",
    "    plt.plot(np.arange(0,1,h)[coor_xstart:coor_xend],np.equal(X, i-1)[coor_xstart:coor_xend], label='Действительное значение', zorder=2, lw=0.5)\n",
    "    plt.plot(np.arange(0,1,h)[coor_xstart:coor_xend],np.equal(argmax,i-1)[coor_xstart:coor_xend], label='Оценка', zorder=1, lw=0.5)\n",
    "    plt.plot(np.arange(0,1,h)[coor_xstart:coor_xend],X_pred[:,i-1][coor_xstart:coor_xend], label='Условная вероятность состояния', alpha=0.5, zorder=0, lw=0.5)\n",
    "    #plt.legend(loc='upper right')\n",
    "    #plt.xlabel('Время (год)')\n",
    "    plt.savefig(str(i)+\"state.pgf\", bbox_inches='tight')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "xstart=0.35\n",
    "xend=0.4\n",
    "\n",
    "coor_xstart = int(xstart / h)\n",
    "coor_xend = int(xend/h)\n",
    "for i in range(1, dim_X+1):\n",
    "    plt.figure(figsize=(12, 1), dpi=240)\n",
    "    #plt.title(\"Результат фильтрации по наблюдениям в случайные моменты времени (\"+str(i)+\"-состояние)\")\n",
    "    plt.plot(np.arange(0,1,h)[coor_xstart:coor_xend],np.equal(X, i-1)[coor_xstart:coor_xend], label='Действительное значение', zorder=2, lw=0.5)\n",
    "    plt.plot(np.arange(0,1,h)[coor_xstart:coor_xend],np.equal(argmax,i-1)[coor_xstart:coor_xend], label='Оценка', zorder=1, lw=0.5)\n",
    "    plt.plot(np.arange(0,1,h)[coor_xstart:coor_xend],X_pred[:,i-1][coor_xstart:coor_xend], label='Условная вероятность состояния', alpha=0.5, zorder=0, lw=0.5)\n",
    "    #plt.legend(loc='upper right')\n",
    "    #plt.xlabel('Время (год)')\n",
    "    plt.savefig(str(i)+\"state_zoom.pgf\", bbox_inches='tight')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9695448"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(argmax == X) * h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bmatrix(a):\n",
    "    \"\"\"Returns a LaTeX bmatrix\n",
    "\n",
    "    :a: numpy array\n",
    "    :returns: LaTeX bmatrix as a string\n",
    "    \"\"\"\n",
    "    if len(a.shape) > 2:\n",
    "        raise ValueError('bmatrix can at most display two dimensions')\n",
    "    lines = str(a).replace('[', '').replace(']', '').splitlines()\n",
    "    rv = [r'\\begin{bmatrix}']\n",
    "    rv += ['  ' + ' & '.join(l.split()) + r'\\\\' for l in lines]\n",
    "    rv +=  [r'\\end{bmatrix}']\n",
    "    return '\\n'.join(rv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.61632 0.00101 0.0005  0.00619]\n",
      " [0.00266 0.00355 0.0009  0.     ]\n",
      " [0.00519 0.00123 0.05896 0.00178]\n",
      " [0.00463 0.      0.00636 0.29072]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "np.set_printoptions(suppress=True, precision=5)\n",
    "print(confusion_matrix(X, argmax, labels=[0,1,2,3])*h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{bmatrix}\n",
      "  0.61632 & 0.00101 & 0.0005 & 0.00619\\\\\n",
      "  0.00266 & 0.00355 & 0.0009 & 0.\\\\\n",
      "  0.00519 & 0.00123 & 0.05896 & 0.00178\\\\\n",
      "  0.00463 & 0. & 0.00636 & 0.29072\\\\\n",
      "\\end{bmatrix}\n"
     ]
    }
   ],
   "source": [
    "print(bmatrix(confusion_matrix(X, argmax, labels=[0,1,2,3])*h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bmatrix(a):\n",
    "    \"\"\"Returns a LaTeX bmatrix\n",
    "\n",
    "    :a: numpy array\n",
    "    :returns: LaTeX bmatrix as a string\n",
    "    \"\"\"\n",
    "    if len(a.shape) > 2:\n",
    "        raise ValueError('bmatrix can at most display two dimensions')\n",
    "    lines = str(a).replace('[', '').replace(']', '').splitlines()\n",
    "    rv = [r'\\begin{bmatrix}']\n",
    "    rv += ['  ' + '\\% & '.join(l.split()) + r'\\%\\\\' for l in lines]\n",
    "    rv +=  [r'\\end{bmatrix}']\n",
    "    return '\\n'.join(rv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{bmatrix}\n",
      "  98.76627\\% & 0.16158\\% & 0.08013\\% & 0.99202\\%\\\\\n",
      "  37.46589\\% & 49.90154\\% & 12.63257\\% & 0.\\%\\\\\n",
      "  7.73275\\% & 1.83038\\% & 87.78653\\% & 2.65034\\%\\\\\n",
      "  1.53478\\% & 0.\\% & 2.10848\\% & 96.35674\\%\\\\\n",
      "\\end{bmatrix}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(bmatrix(confusion_matrix(X, argmax, labels=[0,1,2,3], normalize='true') * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[98.76627  0.16158  0.08013  0.99202]\n",
      " [37.46589 49.90154 12.63257  0.     ]\n",
      " [ 7.73275  1.83038 87.78653  2.65034]\n",
      " [ 1.53478  0.       2.10848 96.35674]]\n"
     ]
    }
   ],
   "source": [
    "a = confusion_matrix(X, argmax, labels=[0,1,2,3], normalize='true') * 100\n",
    "print(str(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
